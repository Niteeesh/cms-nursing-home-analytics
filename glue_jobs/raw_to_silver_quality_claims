import sys
from awsglue.utils import getResolvedOptions
from awsglue.context import GlueContext
from awsglue.job import Job
from pyspark.context import SparkContext
import pyspark.sql.functions as F

# -------------------------------------------------
# Init
# -------------------------------------------------
args = getResolvedOptions(sys.argv, ['JOB_NAME'])

sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)

logger = glueContext.get_logger()

def assert_columns(df, required_cols, df_name):
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        raise ValueError(f"{df_name}: missing columns: {missing}")

try:
    logger.info("JOB STARTED")
# -------------------------------------------------
# Read RAW Claims Quality table from Glue Catalog
# -------------------------------------------------
df = glueContext.create_dynamic_frame.from_catalog(
    database="cms_nh_raw",
    table_name="raw_nh_qualitymsr_claims_oct2024_csv"
).toDF()

# -------------------------------------------------
# Normalize CCN (Text(6), keep leading zeros)
# -------------------------------------------------
df = df.withColumn(
    "ccn",
    F.lpad(
        F.regexp_replace(
            F.col("CMS Certification Number (CCN)").cast("string"),
            "[^0-9]",
            ""
        ),
        6,
        "0"
    )
)

# -------------------------------------------------
# Select, rename, and cast columns
# -------------------------------------------------
df = df.select(
    F.col("ccn"),
    F.col("State").alias("state"),
    F.col("Measure Code").cast("int").alias("measure_code"),
    F.col("Measure Description").alias("measure_description"),
    F.col("Resident type").alias("resident_type"),
    F.col("Observed Score").cast("double").alias("observed_score"),
    F.col("Expected Score").cast("double").alias("expected_score"),
    F.col("Adjusted Score").cast("double").alias("adjusted_score"),
    F.col("Measure Period").alias("measure_period"),
    F.to_date(F.col("Processing Date")).alias("processing_date")
)

# -------------------------------------------------
# Write SILVER Parquet
# -------------------------------------------------
(
    df.write
    .mode("overwrite")
    .format("parquet")
    .partitionBy("state")
    .save("s3://cms-nursing-home-analytics/cms_nh/silver/quality_claims/")
)

logger.info("JOB SUCCEEDED")
job.commit()

except Exception as e:
    logger.error(f"JOB FAILED: {repr(e)}")
    logger.error(traceback.format_exc())
    # Re-raise so Glue marks the run as FAILED
    raise
finally:
    logger.info("JOB FINISHED (finally block)")
