import sys
from awsglue.utils import getResolvedOptions
from awsglue.context import GlueContext
from awsglue.job import Job
from pyspark.context import SparkContext
import pyspark.sql.functions as F

# -------------------------------------------------
# Init
# -------------------------------------------------
args = getResolvedOptions(sys.argv, ['JOB_NAME'])

sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)
logger = glueContext.get_logger()

def assert_columns(df, required_cols, df_name):
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        raise ValueError(f"{df_name}: missing columns: {missing}")

try:
    logger.info("JOB STARTED")
# -------------------------------------------------
# Read RAW Health Citations table
# -------------------------------------------------
df = glueContext.create_dynamic_frame.from_catalog(
    database="cms_nh_raw",
    table_name="raw_nh_healthcitations_oct2024_csv"
).toDF()

# -------------------------------------------------
# Normalize CCN (Text(6), keep leading zeros)
# -------------------------------------------------
df = df.withColumn(
    "ccn",
    F.lpad(
        F.regexp_replace(
            F.col("CMS Certification Number (CCN)").cast("string"),
            "[^0-9]",
            ""
        ),
        6,
        "0"
    )
)

# -------------------------------------------------
# Select, rename, and cast columns
# (Keep event-level grain)
# -------------------------------------------------
df = df.select(
    F.col("ccn"),
    F.col("State").alias("state"),
    F.col("Survey Date").alias("survey_date_raw"),
    F.col("Correction Date").alias("correction_date_raw"),
    F.col("Deficiency Prefix").alias("deficiency_prefix"),
    F.col("Deficiency Tag Number").cast("int").alias("deficiency_tag_number"),
    F.col("Scope Severity Code").alias("scope_severity_code"),
    F.col("Deficiency Category").alias("deficiency_category"),
    F.col("Standard Deficiency").alias("standard_deficiency"),
    F.col("Complaint Deficiency").alias("complaint_deficiency"),
    F.col("infection control inspection deficiency").alias("infection_control_deficiency"),
    F.col("Processing Date").alias("processing_date_raw")
)

# -------------------------------------------------
# Parse dates safely
# -------------------------------------------------
df = (
    df
    .withColumn("survey_date", F.to_date("survey_date_raw"))
    .withColumn("correction_date", F.to_date("correction_date_raw"))
    .withColumn("processing_date", F.to_date("processing_date_raw"))
    .drop("survey_date_raw", "correction_date_raw", "processing_date_raw")
)

# -------------------------------------------------
# Write SILVER Parquet (event-level)
# -------------------------------------------------
(
    df.write
    .mode("overwrite")
    .format("parquet")
    .partitionBy("state")
    .save("s3://cms-nursing-home-analytics/cms_nh/silver/citations_health/")
)

logger.info("JOB SUCCEEDED")
job.commit()

except Exception as e:
    logger.error(f"JOB FAILED: {repr(e)}")
    logger.error(traceback.format_exc())
    # Re-raise so Glue marks the run as FAILED
    raise
finally:
    logger.info("JOB FINISHED (finally block)")
